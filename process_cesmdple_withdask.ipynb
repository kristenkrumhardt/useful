{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/kristenk/miniconda/envs/analysis/lib/python3.7/site-packages/docrep/__init__.py:341: MatplotlibDeprecationWarning: \n",
      "The dedent function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use inspect.cleandoc instead.\n",
      "  s = dedents('\\n' + '\\n'.join(lines[first:]))\n"
     ]
    }
   ],
   "source": [
    "#translates Steve Yeager's NCL scripts into python w/dask\n",
    "#Processes and bias corrects CESM-DPLE output and writes out as a netcdf4\n",
    "#Will work for CAM and POP fields, 2d fields\n",
    "#Should be able to (eventually) handle annual, seasonal, and monthly means\n",
    "#this version does not use dask b/c throughput is the main issue, so limitation\n",
    "#comes from I/O, and adding more processors does not speed things up\n",
    "\n",
    "#I've marked in ALL CAPS places that need to be set by user\n",
    "#-Liz Maroon 9/3/2018\n",
    "\n",
    "#Updated for xarray v0.11.2, 1/23/19\n",
    "#Updated for 2d or 3d POP/CAM annual means\n",
    "\n",
    "\n",
    "#import packages\n",
    "import xarray as xr                   #for netcdf manipulation\n",
    "import numpy as np                    #for numerics\n",
    "from collections import OrderedDict   #for setting netcdf attributes\n",
    "from dask.distributed import Client, LocalCluster   #dask stuff\n",
    "from dask_jobqueue import PBSCluster\n",
    "import os                             #these last three packages used to detect username/script location\n",
    "import pwd\n",
    "import sys\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET VARIABLE INFO HERE:\n",
    "VAR='HMXL' #VAR='TS'\n",
    "MODEL='OCN'# MODEL='ATM' #SET HERE IF PROCESSING CAM OR POP OUTPUT - can write catches for LND/ICE later as needed\n",
    "WHICHMEAN='ANN'  #For ocean monthly means, use a with-dask script #can also do any mean of consecutive months\n",
    "NUMDIMS=2  #2d or 3d variable?\n",
    "\n",
    "#WHERE ARE DPLE FILES CURRENTLY:\n",
    "DPLE_DIR='/glade/scratch/kristenk/dple/netcdf'\n",
    "\n",
    "#WHERE AND WHAT DO YOU WANT TO CALL OUTPUT FILES:\n",
    "DPOUT='/glade/scratch/kristenk/dple_stuff/CESM-DP-LE.'+VAR+'.'+WHICHMEAN.lower()+'mean'#.nc'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for troubleshooting pesky, unexplained dask issues like killed or dropped workers, dangling streams\n",
    "1. Try increasing amount of memory in PBSCluster call\n",
    "2. Increase core/processes ratio in PBSCluster call\n",
    "3. Increase/decrease chunk size in xr.mf_dataset call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/kristenk/miniconda/envs/analysis/lib/python3.7/site-packages/distributed/bokeh/core.py:74: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    }
   ],
   "source": [
    "#cluster = LocalCluster(n_workers=2,threads_per_worker=1)  #for geyser with 2 cores\n",
    "#cluster = LocalCluster(n_workers=36,threads_per_worker=1,diagnostics_port=8861)  #for 1 cheyenne node with 36 cores\n",
    "#cluster = LocalCluster(n_workers=72,threads_per_worker=1)  #for 2 cheyenne node, total 72 cores\n",
    "\n",
    "#for geyser cluster\n",
    "#cluster = SLURMCluster\n",
    "\n",
    "#for cheyenne cluster\n",
    "numnodes=4\n",
    "if NUMDIMS==3: \n",
    "    memory='50GB'\n",
    "else: memory='60GB'\n",
    "\n",
    "cluster=PBSCluster(cores=36,processes=9,memory=memory,project='P93300670',queue='regular',walltime='01:30:00')\n",
    "#cluster.scale(1)\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "cluster.scale(numnodes*9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.148.10.15:39133\n",
       "  <li><b>Dashboard: </b><a href='http://10.148.10.15:38185/status' target='_blank'>http://10.148.10.15:38185/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.148.10.15:39133' processes=0 cores=0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#client.restart()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make array for start years\n",
    "first_syear=1954\n",
    "last_syear=2015\n",
    "S=xr.DataArray(np.arange(first_syear+1,last_syear+1.5,1,dtype='int'),dims=['S'],coords={'S':np.arange(first_syear+1,last_syear+1.5,1,dtype='int')},name='S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix for time bounds #changed zcoord to z_t_150m!!!\n",
    "if MODEL=='OCN': tbname='time_bound'; zcoord='z_t'; latcoord='nlat'; loncoord='nlon'\n",
    "elif MODEL=='ATM': tbname='time_bnds'; zcoord='plev'; latcoord='lat'; loncoord='lon'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#function for seasonal means - come back to later\n",
    "def seamean(dataarray,sea):\n",
    "    monthord='JFMAMJJASOND'\n",
    "    #pri\n",
    "    #mon1=sea[0]\n",
    "    for m2 in monthord:\n",
    "        if m1==m2: break\n",
    "    #mon2=sea[1]\n",
    "    #if \n",
    "monthord='JFMAMJJASOND'\n",
    "for m2 in monthord:\n",
    "    if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35 s, sys: 3.26 s, total: 38.2 s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "oceancoords=['TLAT','TLONG']\n",
    "da_list=[]\n",
    "\n",
    "#for year in S[0:5].values-1:\n",
    "def makeyear(year):\n",
    "    print(year)\n",
    "    loadthesefiles=sorted(glob.glob(f\"{DPLE_DIR}/b.e11.BDP.f09_g16.{year}-11.*.nc\"))\n",
    "    if NUMDIMS==3:\n",
    "        ds=xr.open_mfdataset(loadthesefiles,concat_dim=\"M\", chunks={\"time\": 122,zcoord:1})\n",
    "    else: ds=xr.open_mfdataset(loadthesefiles,concat_dim=\"M\", chunks={\"time\": 24})\n",
    "    ds['time'].values=ds[tbname][0,:,0].values\n",
    "    \n",
    "    ds=ds.assign_coords(M=np.arange(1,len(loadthesefiles)+1,1,dtype='int'))\n",
    "    \n",
    "    #fix for ocean coordinate size xarray bug\n",
    "    if MODEL=='OCN': \n",
    "        for cc in oceancoords:\n",
    "            if len(ds[cc].shape)>2:\n",
    "                tempc=ds[cc][0,:,:].load()\n",
    "                tempd=tempc.dims\n",
    "                ds=ds.drop(cc)\n",
    "                ds=ds.assign_coords(cc=xr.DataArray(tempc.values,coords=[ds[tt].values for tt in tempd],dims=tempd))\n",
    "                ds=ds.rename({'cc':cc})\n",
    "    \n",
    "    da=ds[VAR]\n",
    "    \n",
    "    if 1 in np.shape(ds[VAR]): zdim_sq=True\n",
    "    else: zdim_sq=False\n",
    "    \n",
    "    #removing z_t if present for 2d variable :\n",
    "    if (MODEL=='OCN') and ('z_t' in da.dims) and zdim_sq:\n",
    "        da=da.isel(z_t=0)\n",
    "        da=da.drop('z_t')\n",
    "#     elif ('z_t_150m' in da.dims):\n",
    "#         da=da.isel(z_t_150m=0)\n",
    "#         da=da.drop('z_t_150m')\n",
    "#commented out lines above!! kk\n",
    "     \n",
    "    #get rid of any remaining unwanted dims/coords - want to have left only dims of time, M, lat, lon\n",
    "    for dd in da.coords:\n",
    "        if (dd not in oceancoords) and (dd not in da.dims): da=da.drop(dd)\n",
    "\n",
    "    #time mean\n",
    "    if WHICHMEAN=='ANN':\n",
    "        da=da.groupby('time.year').mean('time').isel(year=slice(1,11))  \n",
    "        #Really should be weighting by months - not doing this for now so can check against Steve's scripts\n",
    "        da=da.rename({'year':'L'})  \n",
    "        da['L'].values=np.arange(1,11,1,dtype='int')\n",
    "                \n",
    "    #add here later for seasonal means\n",
    "    \n",
    "    return da\n",
    "    \n",
    "    #da_list.append(da)\n",
    "da_list=client.map(makeyear,list(S.values-1))\n",
    "da_list=client.gather(da_list)\n",
    "\n",
    "\n",
    "#FOR SST 5S\n",
    "#2 geyser cores: 1 min 19s\n",
    "#36 cheyenne cores: 14 s #50 s\n",
    "#72 cheyenne cores: 40 s\n",
    "#144 cheyenne cores: 30 s\n",
    "\n",
    "#FOR SST all S\n",
    "#144 cheyenne cores: 1 min 9 s\n",
    "\n",
    "#FOR TEMP 5S\n",
    "#72 cheyenne cores : 1 min 25s\n",
    "\n",
    "#FOR TEMP all S\n",
    "#144 cheyenne cores (36/9, 24,1 chunk): 1 min 54 s\n",
    "#144 cheyenne cores (36/9, 50,1 chunk): 1 min 34 s\n",
    "#144 cheyenne cores (36/9, 122,1 chunk): 1 min 30s\n",
    "\n",
    "\n",
    "#FOR TREFHT 5S\n",
    "#144 cheyenne cores: 18 s\n",
    "\n",
    "#FOR TREFHT all S with 144 cores, 36 workers: 17-27 s\n",
    "#144 cheyenne cores: 25 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.79 s, sys: 886 ms, total: 7.68 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#get attributes\n",
    "year=1954\n",
    "loadthesefiles=sorted(glob.glob(f\"{DPLE_DIR}/b.e11.BDP.f09_g16.{year}-11.*.nc\"))\n",
    "ds=xr.open_mfdataset(loadthesefiles,concat_dim=\"M\", chunks={\"time\": 1})\n",
    "\n",
    "ncattrs=ds.attrs\n",
    "varattrs=ds[VAR].attrs\n",
    "dimattrs={}\n",
    "for dd in ds.dims:\n",
    "    dimattrs[dd]=ds[dd].attrs\n",
    "for cc in ds.coords:\n",
    "    dimattrs[cc]=ds[cc].attrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 325 ms, sys: 7.7 ms, total: 333 ms\n",
      "Wall time: 339 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#concatenate list into array by dimension S\n",
    "array=xr.concat(da_list,dim=S)\n",
    "\n",
    "#FOR TEMP all S, 144 cheyenne cores (36/9, chunks 20,1): 31 s\n",
    "#FOR TEMP all S, 144 cheyenne cores (36/9, chunks 122,1): 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUMDIMS==2:\n",
    "    array=array.transpose('S','L','M',latcoord,loncoord)\n",
    "elif NUMDIMS==3:\n",
    "    array=array.transpose('S','L','M',zcoord,latcoord,loncoord)\n",
    "\n",
    "#fast step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 545 µs, sys: 108 µs, total: 653 µs\n",
      "Wall time: 757 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#preparing to turn the DataArray back into a DataSet (so it can be written out as a netcdf)\n",
    "array.name=VAR\n",
    "array.attrs=varattrs\n",
    "dimattrs['S']=OrderedDict([('long_name','start year')])\n",
    "dimattrs['L']=OrderedDict([('long_name','lead year')])\n",
    "dimattrs['M']=OrderedDict([('long_name','ensemble member')])\n",
    "\n",
    "array.attrs=varattrs\n",
    "for cc in array.coords:\n",
    "    array[cc].attrs=dimattrs[cc]\n",
    "\n",
    "#turning DataArray into DataSet and adding ncattrs\n",
    "\n",
    "newds=array.to_dataset()\n",
    "\n",
    "newds.attrs=ncattrs\n",
    "newds.attrs['script']=os.path.basename(sys.argv[0])\n",
    "now=datetime.datetime.now()\n",
    "newds.attrs['history']='created by '+pwd.getpwuid(os.getuid()).pw_name+' on '+str(now)        \n",
    "\n",
    "#fast step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 2.89 ms, total: 2.89 ms\n",
      "Wall time: 30.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "climy0=1964\n",
    "climy1=2014\n",
    "\n",
    "vtime=newds['S']+0.5+newds['L']-1\n",
    "vtime.values[~((vtime.values>climy0) & (vtime.values<(climy1+1)))]=np.nan\n",
    "vtime.values[~np.isnan(vtime.values)]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeallout(ds,fstartname):\n",
    "    ds.to_netcdf(fstartname+'.nc',engine='netcdf4')\n",
    "    ensmean=ds[VAR].mean('M')\n",
    "    drift=(ensmean*vtime).mean('S')\n",
    "    biascorr=ds[VAR]-drift\n",
    "    \n",
    "    ds_drift=drift.to_dataset(name='drift')\n",
    "    ds_drift.attrs['climatology']=str(climy0)+\"-\"+str(climy1)+\", computed separately for each lead time\"\n",
    "    ds_drift.to_netcdf(fstartname+'.drift.nc',engine='netcdf4')\n",
    "    \n",
    "    ds_anom=biascorr.to_dataset(name='anom')\n",
    "    ds_anom.attrs['climatology']=str(climy0)+\"-\"+str(climy1)+\", computed separately for each lead time\"\n",
    "    ds_anom.to_netcdf(fstartname+'.anom.nc',engine='netcdf4')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/kristenk/miniconda/envs/analysis/lib/python3.7/site-packages/xarray/core/nanops.py:159: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 39s, sys: 1min 8s, total: 3min 47s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if NUMDIMS==2: \n",
    "    newds.load()\n",
    "    writeallout(newds,DPOUT)\n",
    "elif NUMDIMS==3:\n",
    "    numlevs=len(newds[zcoord])\n",
    "    #for zz in range(numlevs)[0:2]:\n",
    "    for zz in range(numlevs)[3:16]:\n",
    "        print(zz)\n",
    "        onelevelds=newds.isel({zcoord:zz})\n",
    "        onelevelds.load()\n",
    "        strlev=str(zz+1).zfill(2)\n",
    "        fnamebeg=DPOUT+'.LEV'+strlev\n",
    "        writeallout(onelevelds,fnamebeg)\n",
    "        del onelevelds\n",
    "        \n",
    "#cheyenne 144 cores for 5S SST: 59s\n",
    "#cheyenne 144 cores for all S SST: 3min 23s\n",
    "\n",
    "#cheyenne 144 cores for 5S TREFHT: 50s\n",
    "#cheyenne 144 cores for 12 S TREFHT: 2 min 27s\n",
    "#cheyenne 144 cores for all S TREFHT: 2min 51s\n",
    "\n",
    "#cheyenne 144 cores for 2 layers of TEMP all S (36/9, 122,1 chunks): 1h 7min 17s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.148.10.15:39133\n",
       "  <li><b>Dashboard: </b><a href='http://10.148.10.15:38185/status' target='_blank'>http://10.148.10.15:38185/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>36</li>\n",
       "  <li><b>Cores: </b>144</li>\n",
       "  <li><b>Memory: </b>240.12 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.148.10.15:39133' processes=36 cores=144>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-analysis3]",
   "language": "python",
   "name": "conda-env-miniconda-analysis3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
